name: Scheduled Analytics & Validation

on:
  schedule:
    # Run nightly at 2 AM UTC (9 PM EST)
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  nightly-validation:
    name: Nightly Database Validation
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: retail_admin
          POSTGRES_PASSWORD: validation_password
          POSTGRES_DB: retail_analytics_nightly
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
    steps:
      - name: Checkout main branch
        uses: actions/checkout@v4
        with:
          ref: main
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          pip install psycopg2-binary
          
      - name: Wait for PostgreSQL
        run: |
          until PGPASSWORD=validation_password psql -h localhost -U retail_admin -d retail_analytics_nightly -c '\q'; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done
          
      - name: Apply schema
        env:
          PGPASSWORD: validation_password
        run: |
          echo "Applying database schema..."
          psql -h localhost -U retail_admin -d retail_analytics_nightly -f schema/schema.sql -v ON_ERROR_STOP=1
          
      - name: Load small sample dataset
        env:
          PGHOST: localhost
          PGPORT: 5432
          PGUSER: retail_admin
          PGPASSWORD: validation_password
          PGDATABASE: retail_analytics_nightly
        run: |
          echo "Generating small dataset for validation..."
          if [ -f scripts/generate_data.py ]; then
            python scripts/generate_data.py
          fi
          
      - name: Run KPI queries and capture output
        env:
          PGPASSWORD: validation_password
        run: |
          echo "Running KPI dashboard queries..."
          mkdir -p artifacts
          
          # Run individual queries
          if [ -d queries ]; then
            for sql_file in queries/*.sql; do
              if [ -f "$sql_file" ]; then
                filename=$(basename "$sql_file" .sql)
                echo "Running: $sql_file"
                psql -h localhost -U retail_admin -d retail_analytics_nightly -f "$sql_file" > "artifacts/${filename}_output.txt" 2>&1 || echo "$sql_file had issues"
              fi
            done
          fi
          
      - name: Run validation checks
        env:
          PGPASSWORD: validation_password
        continue-on-error: true
        run: |
          echo "Running data quality validation checks..."
          
          if [ -f validation/data_quality_checks.sql ]; then
            psql -h localhost -U retail_admin -d retail_analytics_nightly -f validation/data_quality_checks.sql > artifacts/validation_output.txt 2>&1
          fi
          
      - name: Generate validation report
        if: always()
        run: |
          cat > artifacts/nightly_report.md << 'EOF'
# Nightly Validation Report

**Date**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
**Branch**: main
**Commit**: ${{ github.sha }}

## Summary

This nightly run validates that:
- Schema applies cleanly
- Sample data loads successfully 
- All queries execute without errors
- Validation checks pass

## Query Results

See attached artifacts for complete query outputs and validation results.
EOF
          
      - name: Archive query outputs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nightly-validation-${{ github.run_number }}
          path: |
            artifacts/**/*.txt
            artifacts/**/*.md
          retention-days: 90
